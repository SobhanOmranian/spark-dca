# Experiment "I/O Activity"

# Overview
The aim of this experiment is assessing how much I/O activity (reads and writes) is generated relative to the input size of different applications.

# Tools
The `pio` command line tool was used to measure the reads and writes of the HDFS (DataNode) process.

# Scripts

#### `pio_executor_hdfs.sh`
Each second, parses the output of the `pio` command and outputs a comma-separated row in the output file at `$RESULT_HOME/OUTPUT_FILE_NAME`.

#### Arguments
The script expects the following positional arguments:

 1. The process ID of the HDFS DataNode.
 2. Name of the output file.
 3. Name of the app.
 4. ID of the executor.

=================================================================

#### `parse-io-activity-results.py`
receives information about the application and produces the final result.

#### Arguments
The script expects the following positional arguments:

 1. Number of input bytes.
 2. Number of output bytes.
 3. Number of output bytes generated by (shuffle) stages.
 4. HDFS replication factor.
 5. Absolute path of the output file.

#### Output
The result is a comma delimited csv string for each application that is saved in the file specified by the 5th positional argument.


# Requirements
* Since this experiment has no plots in the publication, there are no plotting scripts. Therefore, the user needs to directly access the output file generated by `parse-io-activity-results.py` and parse the data.
