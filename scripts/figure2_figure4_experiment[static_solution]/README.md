# Experiment "Static Solution"

# Overview
The aim of this experiment is assessing how the static solution performs compared to the baseline Spark.

# Tools
Once an application is finished running, the script `parse_dca_static_result.py` is called in `../common/spark/run_terasort.pl` with appropriate arguments.

# Scripts

#### `parse_dca_static_result.py`
parses the files produced by `parse-top-result.py` and `../dca/combine.sh` to create a comma-separated row for each stage of an application.

#### Arguments
* --appName, -n: Name of the application
* --adaptive, -a: What mode of adaptivity was used. (100 = both default & static)
* --total_cores, -t: Total available number of cores used to run this application.  
* --topFile, -t: Absolute path of the file generated by the `parse-top-result.py` script.
<sup>[1](#fn1)</sup>
* --outputFile, -o: Absolute path of the output (file) of this script.
<sup>[2](#fn2)</sup>


=================================================================

#### ` plot_dca_static.py`
plots the final figure, based on the data file generated by  the `parse_dca_static_result.py` script.

#### Arguments
* --inputFile, -i: Absolute path of the file generated by the `parse_dca_static_result.py` script.
* --outputFile, -o: Absolute path of the directory where output files will be saved. The file name is formatted in the form of dca_static_`appName`.pdf. For example, 'dca_static_terasort' is the resulting plot for the terasort application.
* --diskType, -d: Type of the disk. Possible values are `hdd` and `ssd`.

=================================================================

# Footnotes
<a name="fn1">1</a>: By default, it is `$RESULT_HOME/resultTop.csv`, but can be changed in `../common/spark/topSetup.pm`.

<a name="fn2">2</a>: By default, it is to be `$RESULT_HOME/resultDcaStatic.csv`, but can be changed in `../common/spark/dcaSetup.pm`

# Requirements
This experiment does not have any special requirements. Make sure the general requirements are met.
